# Minimal configuration for CPU-only systems
# Use this if you don't have a GPU

assistant:
  name: "Assistant"
  wake_words: ["hey assistant"]

backend: "ollama"

ollama:
  base_url: "http://localhost:11434"
  text_model: "qwen2.5:0.5b"  # Smallest model for CPU
  vision_model: null  # Disable vision
  orchestrator_model: "qwen2.5:0.5b"
  orchestrator_num_gpu: 0
  text_temperature: 0.7

whisper:
  model: "tiny.en"  # Smallest whisper model
  device: "cpu"

tts:
  engine: "piper"
  piper:
    voice_path: "~/.local/share/piper/en_US-lessac-medium.onnx"

camera:
  enabled: false  # Disable camera for CPU-only

search:
  enabled: true
  max_results: 3

performance:
  use_gpu: false
  keep_vision_loaded: false
  enable_perf_monitor: true
