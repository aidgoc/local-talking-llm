# üéôÔ∏è Local Talking LLM - Production-Ready Voice Assistant

> **Privacy-First AI Assistant** - Voice-controlled, vision-capable, runs entirely on your hardware. No cloud, no API keys, 100% private.

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![CI](https://img.shields.io/github/actions/workflow/status/yourusername/local-talking-llm/ci.yml?branch=main)](https://github.com/yourusername/local-talking-llm/actions)
[![Platform](https://img.shields.io/badge/platform-Linux%20%7C%20macOS-lightgrey.svg)]()
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

**üìö [Complete User Guide ‚Üí](USER_GUIDE.md)**

---

## ‚ú® Features

### üéØ Core Capabilities
- **üé§ Voice Interaction** - Whisper-based speech recognition (CPU)
- **üí¨ Intelligent Chat** - Powered by Gemma3 (3.3GB) or cloud LLMs
- **üëÅÔ∏è Vision Analysis** - Moondream vision model with camera support
- **üîç Web Search** - DuckDuckGo integration with smart summarization
- **üó£Ô∏è Natural TTS** - Piper neural text-to-speech
- **üß† Memory System** - Persistent memory with semantic search
- **üìù Task Management** - Create, track, and complete tasks
- **üîß Tool Execution** - Time, location, and utility functions

### üèóÔ∏è Production Features (v2.0.0)
- **‚úÖ Structured Logging** - Rotating logs with configurable levels
- **‚úÖ Health Checks** - Startup validation for all dependencies
- **‚úÖ Graceful Degradation** - Continues working even if TTS/search fails
- **‚úÖ Bounded History** - Prevents memory leaks in long sessions
- **‚úÖ Retry Logic** - Auto-retry on transient network failures
- **‚úÖ Signal Handling** - Clean shutdown on SIGTERM/SIGINT
- **‚úÖ Exception Safety** - Session continues after component errors
- **‚úÖ Config Validation** - Early detection of invalid settings
- **‚úÖ Test Suite** - 75+ tests with pytest
- **‚úÖ CI/CD Pipeline** - Automated linting and testing

### üîÑ Dual Backend Support
- **Local (Ollama)** - Complete privacy, no internet required
- **Cloud (OpenRouter)** - Access to powerful models when needed
- **Hybrid (Auto)** - Seamlessly switches based on connectivity

---

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- 4GB+ RAM (8GB recommended)
- GPU with 4GB+ VRAM (optional, for local models)
- Microphone and speakers
- Webcam (optional, for vision features)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/local-talking-llm.git
cd local-talking-llm

# Run the automated installer
chmod +x install.sh
./install.sh

# Or manual installation
python3.11 -m venv .venv311
source .venv311/bin/activate
pip install -e .

# Download local models (for Ollama backend)
ollama pull gemma3
ollama pull moondream
ollama pull qwen2.5:0.5b
```

### First Run

```bash
# Activate environment
source .venv311/bin/activate

# Run with default settings (Ollama backend)
python app_optimized.py

# Or use the launcher script
./run_optimized.sh

# With vision support
python app_optimized.py --vision

# Using cloud backend
python app_optimized.py --backend openrouter --openrouter-key YOUR_KEY

# See all options
python app_optimized.py --help
```

---

## üéÆ LTL CLI (New!)

LTL now includes a powerful command-line interface for advanced users:

```bash
# Initialize workspace
python3 -m ltl init

# Check system status
python3 -m ltl status

# Execute tools directly
python3 -m ltl tool web_search query="python tutorial"
python3 -m ltl tool list_dir path="."
python3 -m ltl tool execute_command command="ls -la"

# Manage configuration
python3 -m ltl config show
python3 -m ltl config edit

# Setup local services
python3 -m ltl setup localai    # Enhanced local LLM
python3 -m ltl setup whisper    # Voice transcription

# Start multi-channel gateway
python3 -m ltl gateway          # Telegram + Discord bots

# See all commands
python3 -m ltl --help
```

**üìö Complete CLI documentation in [USER_GUIDE.md](USER_GUIDE.md)**

---

## üìñ Usage Examples

### Basic Voice Chat
```bash
# Press Enter, speak, press Enter again
python app_optimized.py
```

### Vision Mode
```bash
# Take photos and ask questions about them
python app_optimized.py --vision

# "Take a photo of this document"
# "What do you see?"
# "Describe this image"
```

### Web Search
```bash
# Ask questions that need real-time data
# "What's the weather in London?"
# "Latest news about AI"
# "Current price of Bitcoin"
```

### Memory & Tasks
```bash
# "Remember that my birthday is March 15"
# "What do you remember about me?"
# "Create a task to buy groceries"
# "List my pending tasks"
# "Mark done buy groceries"
```

---

## üèóÔ∏è Architecture

### Resource-Optimized Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Voice Input ‚Üí Whisper (CPU) ‚Üí Intent Classification (CPU)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚Üì                                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Vision  ‚îÇ                          ‚îÇ  Chat   ‚îÇ
‚îÇ Request? ‚îÇ                          ‚îÇ  Text   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì                                    ‚Üì
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ Moondream  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ GPU Swap ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ Gemma3   ‚îÇ
 ‚îÇ  (1.7GB)   ‚îÇ                      ‚îÇ (3.3GB)  ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì                                    ‚Üì
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ  Piper TTS (CPU)      ‚îÇ
           ‚îÇ  Voice Output         ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üîë Key Design Principle

**Only ONE model in GPU memory at a time** due to 4GB VRAM constraint. Models are dynamically swapped based on intent.

---

## üìÅ Project Structure

```
local-talking-llm/
‚îú‚îÄ‚îÄ ü§ñ Application
‚îÇ   ‚îú‚îÄ‚îÄ app_optimized.py           # ‚≠ê Main application (production-ready)
‚îÇ   ‚îú‚îÄ‚îÄ tts.py                     # Text-to-speech module
‚îÇ   ‚îî‚îÄ‚îÄ run_optimized.sh           # Launch script
‚îÇ
‚îú‚îÄ‚îÄ üì¶ Source Code
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py      # Structured logging setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py              # Startup health checks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bounded_history.py     # Memory-bounded chat history
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retry.py               # Retry logic with backoff
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_loader.py       # Config + validation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py        # Intent classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py               # Tool execution system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py            # SQLite persistence
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py        # Semantic search (zvec)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openrouter.py          # Cloud backend client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_search.py          # DuckDuckGo integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connectivity.py        # Network monitoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ piper_tts.py           # Piper TTS wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (other modules)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tests/                     # ‚≠ê 75+ tests with pytest
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_orchestrator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_tools.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_health.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_config_loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_bounded_history.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ default.yaml           # Default configuration
‚îÇ       ‚îî‚îÄ‚îÄ examples/              # Example configs (coming soon)
‚îÇ
‚îú‚îÄ‚îÄ üìö Documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md                  # This file
‚îÇ   ‚îú‚îÄ‚îÄ CLAUDE.md                  # AI assistant guidelines
‚îÇ   ‚îú‚îÄ‚îÄ AI_INSTRUCTIONS.md         # Architecture for AI devs
‚îÇ   ‚îú‚îÄ‚îÄ ROADMAP.md                 # Development roadmap
‚îÇ   ‚îú‚îÄ‚îÄ CHANGELOG.md               # Version history
‚îÇ   ‚îú‚îÄ‚îÄ CONTRIBUTING.md            # Contribution guide
‚îÇ   ‚îî‚îÄ‚îÄ HOW_TO_RUN.md              # Detailed usage guide
‚îÇ
‚îú‚îÄ‚îÄ üîß DevOps
‚îÇ   ‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ci.yml             # CI/CD pipeline
‚îÇ   ‚îú‚îÄ‚îÄ contrib/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ talking-llm.service    # systemd service file
‚îÇ   ‚îú‚îÄ‚îÄ ruff.toml                  # Linter config
‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml             # Package metadata
‚îÇ
‚îî‚îÄ‚îÄ üõ†Ô∏è Setup
    ‚îú‚îÄ‚îÄ install.sh                 # Automated installer
    ‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
    ‚îî‚îÄ‚îÄ LICENSE                    # MIT License
```

---

## ‚öôÔ∏è Configuration

### Configuration File

Create `~/.config/talking-llm/config.yaml` to override defaults:

```yaml
backend: "auto"  # ollama, openrouter, or auto

logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR

chat:
  max_history_messages: 50

ollama:
  base_url: "http://localhost:11434"
  text_model: "gemma3"
  vision_model: "moondream"

openrouter:
  api_key: ""  # Or set OPENROUTER_API_KEY env var
  text_model: "meta-llama/llama-3.3-70b-instruct:free"

whisper:
  model: "base.en"  # tiny.en, base.en, small.en

tts:
  piper:
    voice_path: "~/.local/share/piper/en_US-lessac-medium.onnx"

camera:
  enabled: true
  auto_capture_timeout: 5

search:
  enabled: true
  max_results: 5
```

### Environment Variables

```bash
export OPENROUTER_API_KEY="sk-or-..."
export LLM_BACKEND="auto"  # override backend setting
```

### Command Line Options

```bash
--backend {ollama,openrouter,auto}   # LLM backend
--openrouter-key KEY                 # OpenRouter API key
--model MODEL                        # Override text model
--vision-model MODEL                 # Override vision model
--whisper-model {tiny.en,base.en,small.en}
--no-search                          # Disable web search
--no-vision                          # Disable camera
--config PATH                        # Custom config file
```

---

## üß™ Testing

### Run Tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_orchestrator.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

### Lint Code

```bash
# Check code style
ruff check src/ tests/ app_optimized.py tts.py

# Auto-fix issues
ruff check --fix src/ tests/
```

---

## üê≥ Deployment

### systemd Service (Linux)

```bash
# Copy service file
sudo cp contrib/talking-llm.service /etc/systemd/system/talking-llm@.service

# Enable and start
sudo systemctl enable talking-llm@$USER
sudo systemctl start talking-llm@$USER

# Check logs
sudo journalctl -u talking-llm@$USER -f
```

### Docker (Coming Soon)

```bash
docker-compose up -d
```

---

## üîç Monitoring & Logs

### Log Files

Logs are written to `~/.local/share/talking-llm/logs/assistant.log` with automatic rotation (5MB x 3 backups).

```bash
# View logs
tail -f ~/.local/share/talking-llm/logs/assistant.log

# View with colors
tail -f ~/.local/share/talking-llm/logs/assistant.log | ccze -A
```

### Log Levels

- **DEBUG**: All operations, model loads, detailed timing
- **INFO**: User interactions, intents, responses
- **WARNING**: Degraded functionality (TTS unavailable, etc.)
- **ERROR**: Component failures, exceptions

---

## üö® Troubleshooting

| Issue | Solution |
|-------|----------|
| **"Ollama: FAIL - Cannot connect"** | Start Ollama: `ollama serve` or install from [ollama.ai](https://ollama.ai) |
| **"Model 'gemma3': FAIL - Not pulled"** | Download model: `ollama pull gemma3` |
| **"No microphone detected"** | Check permissions: `arecord -l` (Linux), System Settings > Privacy (macOS) |
| **"Camera failed to open"** | Grant camera access in System Settings, check `/dev/video0` exists |
| **"TTS unavailable"** | Download voice: `install.sh` or manually from [Piper releases](https://github.com/rhasspy/piper/releases) |
| **"Out of VRAM"** | Close other GPU apps, check `nvidia-smi`, or use cloud backend |
| **"Slow performance"** | Use `--whisper-model tiny.en` or cloud backend with `--backend openrouter` |

### Health Check

```bash
# Run health checks
python app_optimized.py 2>&1 | grep -A 20 "Health Checks"

# Check Ollama models
curl http://localhost:11434/api/tags | jq '.models[].name'

# Check GPU memory
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB' if torch.cuda.is_available() else 'CPU only')"
```

---

## üìä Performance Benchmarks

Tested on various hardware configurations:

| Hardware | Text Response | Vision Analysis | TTS | Notes |
|----------|---------------|-----------------|-----|-------|
| RTX 3060 (12GB) | 1.5s | 3s | 0.8s | Fastest, no model swapping |
| GTX 1650 (4GB) | 2.5s | 6s | 0.8s | Model swap overhead |
| MX130 (4GB) | 3.5s | 8s | 0.8s | Target hardware |
| M1 Mac (8GB) | 2s | 4s | 0.8s | Unified memory advantage |
| CPU Only | 8s | 15s | 0.8s | Ollama CPU fallback |
| Cloud (OpenRouter) | 1s | 2s | 0.8s | Network latency |

**Vision is slower** due to model swapping: Gemma3 (3.3GB) must unload before Moondream (1.7GB) loads.

---

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Quick Contribution Guide

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Read** [CLAUDE.md](CLAUDE.md) for architecture constraints
4. **Write** tests for new features
5. **Lint** your code: `ruff check src/ tests/`
6. **Test**: `pytest tests/ -v`
7. **Commit**: `git commit -m "Add amazing feature"`
8. **Push**: `git push origin feature/amazing-feature`
9. **Open** a Pull Request

### Development Setup

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests in watch mode
pytest-watch tests/
```

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **[Ollama](https://ollama.ai)** - Local LLM serving made easy
- **[OpenAI Whisper](https://github.com/openai/whisper)** - Robust speech recognition
- **[Piper TTS](https://github.com/rhasspy/piper)** - High-quality neural TTS
- **[Moondream](https://github.com/vikhyat/moondream)** - Lightweight vision model
- **[LangChain](https://langchain.com)** - LLM orchestration framework
- **[zvec](https://github.com/IntrinsicLabsAI/zvec)** - Fast semantic search

---

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/local-talking-llm/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/local-talking-llm/discussions)
- **Security**: See [SECURITY.md](SECURITY.md) for reporting vulnerabilities

---

## üó∫Ô∏è Roadmap

See [ROADMAP.md](ROADMAP.md) for upcoming features and development plans.

### Coming Soon (v2.1.0)
- [ ] Docker support with docker-compose
- [ ] Wake word detection improvements
- [ ] Multi-language support
- [ ] Voice cloning with Piper
- [ ] Plugin system for custom tools

---

## ‚≠ê Star History

If you find this project useful, please consider giving it a star!

---

**Status**: ‚úÖ Production Ready | **Version**: 2.0.0 | **Python**: 3.11+

**Made with ‚ù§Ô∏è for privacy-conscious AI enthusiasts**
